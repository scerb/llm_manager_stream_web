{
  "models": [
    {
      "name": "llava-v1.5-7b-q4",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8900,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./llava-v1.5-7b-q4.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --nobrowser --mlock -ngl 9999 -c 4096",
      "env": {},
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.5,
      "max_tokens": 1536,
      "vram_gb": 6,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-14B-Q4_K_M",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8901,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./DeepSeek-R1-Distill-Qwen-14B-Q4_K_M.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {},
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.6,
      "max_tokens": 2048,
      "vram_gb": 15,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "Qwen2.5-Coder-14B-Instruct-Q4_K_M",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8902,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./Qwen2.5-Coder-14B-Instruct-Q4_K_M.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {},
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 2048,
      "vram_gb": 14,
      "weights_path": null,
      "preload_to_ram": false,
      "preload_binary_to_ram": false,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "DeepSeek-R1-Distill-Llama-8B-Q4_K_M",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8903,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./DeepSeek-R1-Distill-Llama-8B-Q4_K_M.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {
        "GGML_CUDA_FORCE_CUBLAS": "1",
        "GGML_CUDA_FORCE_MMQ": "0",
        "CUDA_MODULE_LOADING": "EAGER"
     },
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 1536,
      "vram_gb": 13,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "google_gemma-3-4b-it-Q6_K",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8904,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./google_gemma-3-4b-it-Q6_K.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock --verbose -ngl 9999 -c 4096",
      "env": {
        "GGML_CUDA_FORCE_CUBLAS": "1",
        "GGML_CUDA_FORCE_MMQ": "0",
        "CUDA_MODULE_LOADING": "EAGER"
     },
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 1536,
      "vram_gb": 10,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "google_gemma-3-12b-it-Q4_K_M",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8905,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./google_gemma-3-12b-it-Q4_K_M.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {
        "GGML_CUDA_FORCE_CUBLAS": "1",
        "GGML_CUDA_FORCE_MMQ": "0",
        "CUDA_MODULE_LOADING": "EAGER"
     },
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 2048,
      "vram_gb": 15,
      "weights_path": null,
      "preload_to_ram": false,
      "preload_binary_to_ram": false,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "granite-3.2-8b-instruct-Q4_K_M",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8906,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./granite-3.2-8b-instruct-Q4_K_M.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {},
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 1536,
      "vram_gb": 9,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "Meta-Llama-3.1-8B-Instruct.Q4_K_M",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8907,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./Meta-Llama-3.1-8B-Instruct.Q4_K_M.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {
        "GGML_CUDA_FORCE_CUBLAS": "1",
        "GGML_CUDA_FORCE_MMQ": "0",
        "CUDA_MODULE_LOADING": "EAGER"
     },
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 1536,
      "vram_gb": 12,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "Mistral-7B-Instruct-v0.3.Q4_0",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8908,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./Mistral-7B-Instruct-v0.3.Q4_0.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {},
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 1536,
      "vram_gb": 15,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "Qwen2.5-7B-Instruct-1M-Q4_K_M",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8909,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./Qwen2.5-7B-Instruct-1M-Q4_K_M.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {},
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 2048,
      "vram_gb": 8.5,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    },
    {
      "name": "Qwen_Qwen3-4B-Q8_0",
      "api_type": "openai_compat",
      "host": "127.0.0.1",
      "port": 8910,
      "ready_path": "/v1/models",
      "completion_path": "/v1/chat/completions",
      "api_key": null,
      "binary_path": "./Qwen_Qwen3-4B-Q8_0.llamafile",
      "launch_cmd": "{binary} --host {host} --port {port} --mlock -ngl 9999 -c 4096",
      "env": {},
      "startup_timeout_s": 12,
      "shutdown_grace_s": 5.0,
      "temperature": 0.7,
      "max_tokens": 2048,
      "vram_gb": 9,
      "weights_path": null,
      "preload_to_ram": true,
      "preload_binary_to_ram": true,
      "prefer_bin_copy_to_tmpfs": true,
      "prepared_weights_path": null
    }
  ],
  "requests_file": "requests.txt",
  "output_dir": "outputs",
  "logs_dir": "logs",
  "system_specs_path": "system_specs.json",
  "vram_reserve_gb": 1.0,
  "safety_vram_margin_gb": 0.5,
  "allow_oversubscription": false,
  "evict_and_retry_on_start_failure": true,
  "exclusive_mode": true,
  "fairness_timeslice_s": 5.0,
  "starvation_avoidance_min_other": 1,
  "web_host": "127.0.0.1",
  "web_port": 8765,
  "web_title": "LLM Manager â€“ Live Stream",
  "process_existing_requests_on_start": true,
  "start_with_clean_outputs": false,
  "ram_cache_tmpfs_dir": "/dev/shm/llm_cache",
  "bin_cache_tmpfs_dir": "/dev/shm/llm_bin_cache",
  "pagecache_warm_block_mb": 8,
  "gpu_override": null
}
